{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d083654",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c2f9f",
   "metadata": {},
   "source": [
    "# <center> Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fe502",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow - Aur√©lien G√©ron\n",
    "* Machine learning - Fast reference guide - Matt Harrison\n",
    "* https://filipezabala.com/\n",
    "* https://www.youtube.com/@patloeber\n",
    "* https://www.youtube.com/@Dataquestio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a285b21",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3685fa",
   "metadata": {},
   "source": [
    "Naive Bayes is a probabilistic supervised learning classification model. Based on Bayes' theorem, the model assumes independence among the attributes and describes the probability of an event conditioned on prior knowledge that may be related to the event.\n",
    "\n",
    "Scikit-learn (sklearn) provides three variations of the model:\n",
    "\n",
    "* GaussianNB: For continuous attributes with a normal distribution.\n",
    "\n",
    "* MultinomialNB: For discrete occurrence counters.\n",
    "\n",
    "* BernoulliNB: For discrete Boolean attributes.\n",
    "\n",
    "Some data transformations can be convenient, such as excluding collinear attributes, normalizing the distribution for GaussianNB model, and discretizing continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b768653e",
   "metadata": {},
   "source": [
    "## Some math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd863e5",
   "metadata": {},
   "source": [
    "Here are some perspectives on the mathematical formulation of the Bayes' model.\n",
    "\n",
    "## $ P(A|X) = \\frac{P(X|A)  P(A)}{P(X)} $ \n",
    "\n",
    "## $ P(A_{j}|X) = \\Pi{P(x_i|A_j)} $ \n",
    "\n",
    "## $ P(A|x_1, x_2, ... , x_n) = \\frac{P(x_1|A)P(x_2|A)...P(x_n|A)}{P(x_1)P(x_2) ... P(x_n)} $ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5bd1c",
   "metadata": {},
   "source": [
    "Using a more formal formulation:\n",
    "\n",
    "## $ \\Pi(\\theta|X) = \\frac{L(X|\\theta)  \\Pi(\\theta)}{\\int_{\\theta}L(X|\\theta)\\Pi(\\theta)d\\theta} $ \n",
    "\n",
    "\n",
    "## $ Posteriori = \\frac{Verossimilhan√ßa X Priori}{Evidencia} $ \n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\Pi$: It is a probability distribution. It is the translation of opinion through the probability distribution. The subjectivist aspect behind Bayesian probability.\n",
    "\n",
    "\n",
    "* $ \\Pi(\\theta)$ - **Priori**: Opinion or probability distribution before observing the data.\n",
    "\n",
    "\n",
    "* $ \\Pi(\\theta|X) $ - **Posteriori**: Opinion or probability distribution after observing the data.\n",
    "\n",
    "\n",
    "* $ L(X|\\theta) $ - **Likelihood**: It is the information from the data. The information of the particular variable conditioned on the unknown population parameter ùúÉ. In the Bayesian view, we cannot make different decisions with the same prior opinion after observing the data.\n",
    "\n",
    "\n",
    "* $ \\int_{\\theta}L(X|\\theta)\\Pi(\\theta)d\\theta $ - **Evidence**: Probability of the true ùúÉ. With appropriate choice of probability distribution and given mechanistic data, the numerator disappears, and the *posteriori* becomes the product of the *prior* and the *likelihood*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245e68e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e721b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db36a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd094e48",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01fb2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load data\n",
    "bc = datasets.load_breast_cancer()\n",
    "\n",
    "# Define X and y\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "# Separate train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8117f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1002b0",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567c899",
   "metadata": {},
   "source": [
    "## From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a85ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from my_BayesianModels import accuracy, NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041c9fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.596%\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "nb = NaiveBayes()\n",
    "\n",
    "# Fit\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy(y_test, predictions)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy: %.3f%%\" % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc856b1",
   "metadata": {},
   "source": [
    "## From Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58622157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150004b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.596%\n"
     ]
    }
   ],
   "source": [
    "# Define Multinomial model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Treinamento do modelo\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "pred = nb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = nb.score(X_test, y_test)\n",
    "\n",
    "# Print score \n",
    "print(\"Accuracy: %.3f%%\" % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8311129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.351%\n"
     ]
    }
   ],
   "source": [
    "# Define Gaussian model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Treinamento do modelo\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "pred = nb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = nb.score(X_test, y_test)\n",
    "\n",
    "# Print score \n",
    "print(\"Accuracy: %.3f%%\" % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed92e00",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
